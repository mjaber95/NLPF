{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLPF_05_P.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNuSDIsQhIneiE5bIpERfcf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/satuelisa/NLPF/blob/main/NLPF_05_P.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gutenbergpy # do not redo this if on your own computer, we already used it in Session 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Evn0ji3As6j9",
        "outputId": "5a6bafaf-2942-4fc4-be54-5f41dbfa5c3f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting gutenbergpy\n",
            "  Downloading gutenbergpy-0.3.4-py3-none-any.whl (21 kB)\n",
            "Requirement already satisfied: pymongo in /usr/local/lib/python3.7/dist-packages (from gutenbergpy) (4.2.0)\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.7/dist-packages (from gutenbergpy) (3.0.4)\n",
            "Requirement already satisfied: future>=0.15.2 in /usr/local/lib/python3.7/dist-packages (from gutenbergpy) (0.16.0)\n",
            "Requirement already satisfied: lxml>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from gutenbergpy) (4.2.6)\n",
            "Collecting httpsproxy-urllib2\n",
            "  Downloading httpsproxy_urllib2-1.0.tar.gz (28 kB)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from gutenbergpy) (57.4.0)\n",
            "Building wheels for collected packages: httpsproxy-urllib2\n",
            "  Building wheel for httpsproxy-urllib2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for httpsproxy-urllib2: filename=httpsproxy_urllib2-1.0-py3-none-any.whl size=29269 sha256=916672b2b7a8f4dedb475ff574d989cec60e76be1c298987c11755637643639a\n",
            "  Stored in directory: /root/.cache/pip/wheels/91/04/37/b7080e0cfe33a8bc79ff0082159cea767f9145a5a713b501a3\n",
            "Successfully built httpsproxy-urllib2\n",
            "Installing collected packages: httpsproxy-urllib2, gutenbergpy\n",
            "Successfully installed gutenbergpy-0.3.4 httpsproxy-urllib2-1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gutenbergpy.textget # reuse Session 1 stuff again\n",
        "target = 36 # this one is The War of the Worlds by H.G. Wells\n",
        "raw  = gutenbergpy.textget.get_text_by_id(target) # content\n",
        "text = gutenbergpy.textget.strip_headers(raw) # remove header\n",
        "s = text.decode(\"utf-8\") # string"
      ],
      "metadata": {
        "id": "FFnuHnQbtCAa"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "l = len(s)\n",
        "margin = 500\n",
        "midpoint = s[(l - margin):(l + margin)]\n",
        "print(midpoint)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5wKCMniOtWIM",
        "outputId": "43024e94-ca60-499c-8472-904f2a8ff924"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " vanishing at last into the vague lower sky, to see the people\n",
            "walking to and fro among the flower beds on the hill, to see the\n",
            "sight-seers about the Martian machine that stands there still, to hear\n",
            "the tumult of playing children, and to recall the time when I saw it\n",
            "all bright and clear-cut, hard and silent, under the dawn of that last\n",
            "great day. . . .\n",
            "\n",
            "And strangest of all is it to hold my wifeâ€™s hand again, and to think\n",
            "that I have counted her, and that she has counted me, among the dead.\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "OK, we have some ideas for words now. Let's see what we can dig up regarding *tumult* in `WordNet`."
      ],
      "metadata": {
        "id": "NswqOmtbtxWc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk # this we already have\n",
        "nltk.download('wordnet') # this is new, download once per environment\n",
        "nltk.download('omw-1.4') # same here"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CB3uMvsAuIS5",
        "outputId": "48a35c18-f349-4575-be56-cac4bde38652"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word = 'tumult'\n",
        "from nltk.corpus import wordnet as wn\n",
        "ss = wn.synsets(word)\n",
        "print(ss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fUJdQD_At6bM",
        "outputId": "790b65c1-693b-4d0a-d267-08fcab09ee1a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Synset('tumult.n.01'), Synset('tumult.n.02'), Synset('commotion.n.02')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "What words do these \"sets of meaning\" contain?"
      ],
      "metadata": {
        "id": "0cyk5rIbuZAe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for batch in ss:\n",
        "  print(batch.lemma_names())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ePTg_mBpuYBN",
        "outputId": "5cd190af-ef98-4d0e-b556-0f2636ed37fd"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['tumult', 'tumultuousness', 'uproar', 'garboil']\n",
            "['tumult', 'turmoil']\n",
            "['commotion', 'din', 'ruction', 'ruckus', 'rumpus', 'tumult']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "What is the *meaning* of these?"
      ],
      "metadata": {
        "id": "HpL1RtfFulsx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for batch in ss:\n",
        "  print(batch.definition())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7FXziiBeupAQ",
        "outputId": "4095f07d-2ac8-468b-aadd-387e3898d13c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a state of commotion and noise and confusion\n",
            "violent agitation\n",
            "the act of making a noisy disturbance\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's focus on the last one: *commotion* that means \"the act of making a noisy disturbance\". What words would be more specific versions of this concepts?"
      ],
      "metadata": {
        "id": "7TvknTPKu2Ky"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "example = ss[-1]\n",
        "print(example.hyponyms())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "APDutZ-AvPLz",
        "outputId": "e0c6c333-eaba-4160-ed02-ad7d967d10b8"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Synset('bustle.n.01')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "How about more general terms for this type of racket?"
      ],
      "metadata": {
        "id": "C_685CupvcrO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(example.hypernyms())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pS6XQGr1vfni",
        "outputId": "4b3fd775-741d-4552-9f6e-dbc1a29fbbe5"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Synset('disturbance.n.05')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's try another word, \"machine\". What are possible *components* of a machine?"
      ],
      "metadata": {
        "id": "vBQH1EYJvvKR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "w2 = 'machine'\n",
        "s2 = wn.synsets(w2)\n",
        "for s in s2:\n",
        "  parts = [ s.part_meronyms(), s.substance_meronyms() ]\n",
        "  for subset in parts:\n",
        "    if len(subset) > 0:\n",
        "      for p in subset:\n",
        "        print(p.lemma_names())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fy9HEixyv4gj",
        "outputId": "60926bf1-19af-4a2e-d3a3-9ad026653c01"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['accelerator', 'accelerator_pedal', 'gas_pedal', 'gas', 'throttle', 'gun']\n",
            "['air_bag']\n",
            "['auto_accessory']\n",
            "['automobile_engine']\n",
            "['automobile_horn', 'car_horn', 'motor_horn', 'horn', 'hooter']\n",
            "['buffer', 'fender']\n",
            "['bumper']\n",
            "['car_door']\n",
            "['car_mirror']\n",
            "['car_seat']\n",
            "['car_window']\n",
            "['fender', 'wing']\n",
            "['first_gear', 'first', 'low_gear', 'low']\n",
            "['floorboard']\n",
            "['gasoline_engine', 'petrol_engine']\n",
            "['glove_compartment']\n",
            "['grille', 'radiator_grille']\n",
            "['high_gear', 'high']\n",
            "['hood', 'bonnet', 'cowl', 'cowling']\n",
            "['luggage_compartment', 'automobile_trunk', 'trunk']\n",
            "['rear_window']\n",
            "['reverse', 'reverse_gear']\n",
            "['roof']\n",
            "['running_board']\n",
            "['stabilizer_bar', 'anti-sway_bar']\n",
            "['sunroof', 'sunshine-roof']\n",
            "['tail_fin', 'tailfin', 'fin']\n",
            "['third_gear', 'third']\n",
            "['window']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The other way around, we can also query for \"container terms\": what concept can contain a specific word as its component?"
      ],
      "metadata": {
        "id": "QgDFqPNfwcb4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import RegexpTokenizer\n",
        "\n",
        "tokenizer = RegexpTokenizer(r'\\w+') # remove punctuation\n",
        "words = tokenizer.tokenize(midpoint)\n",
        "\n",
        "for w in words:\n",
        "  ss = wn.synsets(w)\n",
        "  for s in ss:\n",
        "    c = s.member_holonyms()\n",
        "    if len(c) > 0:\n",
        "      print(w, c)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4jR_VKtjwgXN",
        "outputId": "d0e76d30-48a6-49c1-b793-364464333f24"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "people [Synset('world.n.08')]\n",
            "children [Synset('family.n.02')]\n",
            "I [Synset('roman_alphabet.n.01')]\n",
            "s [Synset('roman_alphabet.n.01')]\n",
            "I [Synset('roman_alphabet.n.01')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "How about concepts that *entail* other concepts?"
      ],
      "metadata": {
        "id": "aLPgX11-yqTG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for w in words:\n",
        "  ss = wn.synsets(w)\n",
        "  for s in ss:\n",
        "    c = s.entailments()\n",
        "    if len(c) > 0:\n",
        "      for ss2 in c:\n",
        "        print(w, ss2.lemma_names())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ULimlxh6y7jG",
        "outputId": "07af099d-f1a8-4b71-afef-2ef097aa3155"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "last ['be', 'live']\n",
            "see ['look']\n",
            "walking ['step']\n",
            "see ['look']\n",
            "stands ['arise', 'rise', 'uprise', 'get_up', 'stand_up']\n",
            "playing ['compete', 'vie', 'contend']\n",
            "saw ['look']\n",
            "clear ['evaluate', 'pass_judgment', 'judge']\n",
            "last ['be', 'live']\n",
            "hold ['procure', 'secure']\n",
            "have ['perceive', 'comprehend']\n",
            "have ['conceive']\n",
            "has ['perceive', 'comprehend']\n",
            "has ['conceive']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Well, since there are synonym relations (two words with similar meanings), there should naturally also be information on the *antonyms* that carry a contrary meaning,"
      ],
      "metadata": {
        "id": "lpvHvx8lzKNe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for w in words:\n",
        "  if len(w) < 5:\n",
        "    continue # only process longer words\n",
        "  ss = wn.synsets(w)\n",
        "  for s in ss:\n",
        "    for l in s.lemmas():\n",
        "      a = l.antonyms()\n",
        "      if len(a) > 0:\n",
        "        print(w, a)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hjNllDDLzU53",
        "outputId": "d09f9548-d0b8-4692-dd86-2884cf08dc48"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "vanishing [Lemma('appear.v.02.appear')]\n",
            "vanishing [Lemma('appear.v.05.appear')]\n",
            "vague [Lemma('defined.a.01.defined')]\n",
            "lower [Lemma('raise.v.02.raise')]\n",
            "lower [Lemma('high.a.01.high')]\n",
            "lower [Lemma('high.a.02.high')]\n",
            "lower [Lemma('high.a.04.high')]\n",
            "walking [Lemma('ride.v.02.ride')]\n",
            "stands [Lemma('sit.v.01.sit'), Lemma('lie.v.02.lie')]\n",
            "stands [Lemma('yield.v.05.yield')]\n",
            "there [Lemma('here.n.01.here')]\n",
            "there [Lemma('here.r.01.here')]\n",
            "there [Lemma('here.r.03.here')]\n",
            "still [Lemma('agitate.v.02.agitate')]\n",
            "still [Lemma('louden.v.02.louden')]\n",
            "still [Lemma('moving.a.03.moving')]\n",
            "still [Lemma('sparkling.a.02.sparkling')]\n",
            "still [Lemma('no_longer.r.01.no_longer')]\n",
            "children [Lemma('parent.n.01.parent')]\n",
            "recall [Lemma('forget.v.02.forget')]\n",
            "recall [Lemma('issue.v.02.issue')]\n",
            "bright [Lemma('dull.a.02.dull')]\n",
            "bright [Lemma('dimmed.a.01.dimmed')]\n",
            "clear [Lemma('clutter.v.01.clutter')]\n",
            "clear [Lemma('overcast.v.01.overcast')]\n",
            "clear [Lemma('bounce.v.04.bounce')]\n",
            "clear [Lemma('convict.v.01.convict')]\n",
            "clear [Lemma('unclear.a.02.unclear')]\n",
            "clear [Lemma('opaque.a.01.opaque')]\n",
            "clear [Lemma('ill-defined.a.01.ill-defined')]\n",
            "clear [Lemma('cloudy.a.02.cloudy')]\n",
            "strangest [Lemma('familiar.a.02.familiar')]\n",
            "strangest [Lemma('native.a.01.native')]\n",
            "think [Lemma('forget.v.02.forget')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "How can we figure out the *distance* between words? First we have to figure out how deep they are with respect to their root concepts."
      ],
      "metadata": {
        "id": "koQG21f_0wBn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "words = [ 'chicken', 'dragon', 'princess', 'pie', 'egg' ]\n",
        "wss = [ wn.synsets(w) for w in words ]\n",
        "for (w, ss) in zip(words, wss):\n",
        "  for s in ss:\n",
        "    print(f'{w} is {s.min_depth()} down from {s.root_hypernyms()}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dBx_aLyQ04yF",
        "outputId": "5e7571b7-74b3-4bc6-ed70-d5e2889cc4f0"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "chicken is 8 down from [Synset('entity.n.01')]\n",
            "chicken is 12 down from [Synset('entity.n.01')]\n",
            "chicken is 5 down from [Synset('entity.n.01')]\n",
            "chicken is 6 down from [Synset('entity.n.01')]\n",
            "chicken is 0 down from [Synset('chicken.s.01')]\n",
            "dragon is 10 down from [Synset('entity.n.01')]\n",
            "dragon is 7 down from [Synset('entity.n.01')]\n",
            "dragon is 6 down from [Synset('entity.n.01')]\n",
            "dragon is 14 down from [Synset('entity.n.01')]\n",
            "princess is 6 down from [Synset('entity.n.01')]\n",
            "pie is 7 down from [Synset('entity.n.01')]\n",
            "pie is 6 down from [Synset('entity.n.01')]\n",
            "egg is 9 down from [Synset('entity.n.01')]\n",
            "egg is 6 down from [Synset('entity.n.01')]\n",
            "egg is 8 down from [Synset('entity.n.01')]\n",
            "egg is 4 down from [Synset('move.v.02')]\n",
            "egg is 2 down from [Synset('cover.v.01')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "So, now all the ones that are *entities* should have have a similarity measure that reflects how far apart they are from each other in the hierarchy of meaning."
      ],
      "metadata": {
        "id": "KtAA_a5H17CM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "d = dict(zip(words, wss))\n",
        "similarities = dict()\n",
        "for w1 in words:\n",
        "  ss1 = d[w1]\n",
        "  for w2 in words:\n",
        "    if w1 == w2:\n",
        "      continue\n",
        "    ss2 = d[w2]\n",
        "    for (s1, s2) in zip(ss1, ss2): \n",
        "      r1 = s1.root_hypernyms()[0]\n",
        "      r2 = s2.root_hypernyms()[0]\n",
        "      if r1 == r2:\n",
        "        sim = s1.path_similarity(s2) # a value in [0, 1], 1 meaning \"the same\"\n",
        "        key = (w1, w2, r1)\n",
        "        value = max(sim, similarities.get(key, 0)) # highest \n",
        "        similarities[key] = value\n",
        "\n",
        "for (w1, w2, root), value in similarities.items():\n",
        "  print(f'Similarity of {w1} with {w2} is {value} in the hierarchy of {root}')\n",
        "\n",
        "# extreme cases\n",
        "print('Highest similarity', max(similarities, key = similarities.get))\n",
        "print('Lowest similarity', min(similarities, key = similarities.get))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HFIBV-fw10i0",
        "outputId": "04e1a7c3-436f-4595-8fed-6b333fcfa819"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity of chicken with dragon is 0.1111111111111111 in the hierarchy of Synset('entity.n.01')\n",
            "Similarity of chicken with princess is 0.07692307692307693 in the hierarchy of Synset('entity.n.01')\n",
            "Similarity of chicken with pie is 0.125 in the hierarchy of Synset('entity.n.01')\n",
            "Similarity of chicken with egg is 0.08333333333333333 in the hierarchy of Synset('entity.n.01')\n",
            "Similarity of dragon with chicken is 0.1111111111111111 in the hierarchy of Synset('entity.n.01')\n",
            "Similarity of dragon with princess is 0.058823529411764705 in the hierarchy of Synset('entity.n.01')\n",
            "Similarity of dragon with pie is 0.07142857142857142 in the hierarchy of Synset('entity.n.01')\n",
            "Similarity of dragon with egg is 0.08333333333333333 in the hierarchy of Synset('entity.n.01')\n",
            "Similarity of princess with chicken is 0.07692307692307693 in the hierarchy of Synset('entity.n.01')\n",
            "Similarity of princess with dragon is 0.058823529411764705 in the hierarchy of Synset('entity.n.01')\n",
            "Similarity of princess with pie is 0.08333333333333333 in the hierarchy of Synset('entity.n.01')\n",
            "Similarity of princess with egg is 0.09090909090909091 in the hierarchy of Synset('entity.n.01')\n",
            "Similarity of pie with chicken is 0.125 in the hierarchy of Synset('entity.n.01')\n",
            "Similarity of pie with dragon is 0.07142857142857142 in the hierarchy of Synset('entity.n.01')\n",
            "Similarity of pie with princess is 0.08333333333333333 in the hierarchy of Synset('entity.n.01')\n",
            "Similarity of pie with egg is 0.07692307692307693 in the hierarchy of Synset('entity.n.01')\n",
            "Similarity of egg with chicken is 0.08333333333333333 in the hierarchy of Synset('entity.n.01')\n",
            "Similarity of egg with dragon is 0.08333333333333333 in the hierarchy of Synset('entity.n.01')\n",
            "Similarity of egg with princess is 0.09090909090909091 in the hierarchy of Synset('entity.n.01')\n",
            "Similarity of egg with pie is 0.07692307692307693 in the hierarchy of Synset('entity.n.01')\n",
            "Highest similarity ('chicken', 'pie', Synset('entity.n.01'))\n",
            "Lowest similarity ('dragon', 'princess', Synset('entity.n.01'))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "JsacwRA84R9x"
      }
    }
  ]
}