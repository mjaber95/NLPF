# NLPF
Natural Language Processing Fundamentals

# Bibliography


# Data sets

- [Project Gutenberg](https://www.gutenberg.org/ebooks/): the raw text of numerous books

# Concepts

- *token* = a meaningful unit (of text)
- *tokenization* = the process of extracting tokens from text
- *string* = a data representation for a sequence of characters
- *metadata* = tags or other type of data associated to a string or a token describing its origin, meaning, or some other characteristic thereof
- *corpus* = a collection of textual data that contains strings, possibly with associated metadata
- *stopword* = a word the presence of which is deemed meaningless in a given context
