# NLPF
Natural Language Processing Fundamentals

# Tools and libraries

For each library, the parenthesis indicates the sessions that employ the package

1. [Python](https://www.python.org/)
* numpy (S1)
* pandas (S1) 
* matplotlib (S1)
* gutenbergpy (S1)
2. [R](https://www.r-project.org/)
* gutenbergr (S1)
* tidytext (S1)
* ggplot2 (S1)
* quanteda (S1)
* quanteda.textplot (S1)

You can either run things on an online environment like Google Colab or install both of these open-source tools on your own computer.

# Bibliography

![R](https://learning.oreilly.com/covers/urn:orm:book:9781491981641/200w/) | ![Python](https://learning.oreilly.com/covers/urn:orm:book:9780596803346/200w/)
:------------------:|:------------------:
[Text Mining with R](https://learning.oreilly.com/library/view/text-mining-with/9781491981641/) | [NLP with Python](https://learning.oreilly.com/library/view/natural-language-processing/9780596803346/)



# Data sets

- [Project Gutenberg](https://www.gutenberg.org/ebooks/): the raw text of numerous books

# Concepts

- *token* = a meaningful unit (of text)
- *tokenization* = the process of extracting tokens from text
- *string* = a data representation for a sequence of characters
- *metadata* = tags or other type of data associated to a string or a token describing its origin, meaning, or some other characteristic thereof
- *corpus* = a collection of textual data that contains strings, possibly with associated metadata
- *stopword* = a word the presence of which is deemed meaningless in a given context
- *term-document matrix* = a matrix in which each row represents a document and each column represents a term, with the cells indicating the frequency of occurrence of each term in each document
